{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Representations (Doc2Vec) : Sentence(or list of sents) by Sentence Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOCUMENTATION \n",
    "https://radimrehurek.com/gensim/models/doc2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "# --- NLTK PACKAGE ---\n",
    "import nltk\n",
    "# Tokenizers\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, PunktSentenceTokenizer, RegexpTokenizer\n",
    "# Stemming and Lemmatizing\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# Stopwords\n",
    "from nltk.corpus import stopwords, state_union, brown, movie_reviews, treebank\n",
    "\n",
    "# --- GENSIM PACKAGE ---\n",
    "import gensim, logging\n",
    "from gensim.models import Word2Vec, doc2vec, Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Documents(DataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## List of Full names of doc-files in the folder \"Documents\"\n",
    "\n",
    "docLabels = []\n",
    "docLabels = [file for file in listdir(\"Documents\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Book_1', 'Book_3', 'Book_2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for doc in docLabels:\n",
    "    path = \"Documents/\" + doc\n",
    "    data.append(open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' KEY--\n",
    "    \n",
    "    data        : Contains the list of all documents\n",
    "    data[0]     : First string document, i.e Book 1\n",
    "    labels_list : Contains the list of labels('Book_1','Book_2','Book_3')\n",
    "    words       : List of all words in one document('word1', 'word2', ...., 'wordn')\n",
    "    labels      : Assigned 'label_list[i]' to words[i]\n",
    "'''\n",
    "\n",
    "class DocIterator(object):\n",
    "    \n",
    "    ## Initailizes document's list(doc1,doc2...) and its label's list('Book_1','Book_2',...)\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.doc_list = doc_list\n",
    "        self.labels_list = labels_list\n",
    "    \n",
    "    ## Assigns label1 to a list of all words in doc1, label2 to all words in doc2, etc.\n",
    "    def __iter__(self):\n",
    "        \n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield doc2vec.LabeledSentence(words=doc.read().split(), tags=[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''The input to Doc2Vec is iteration of objects, and each object consists of two simple lists.\n",
    "   The two simple lists are: List of all words of a doc & List of labels.\n",
    "   'iter_docs' is an object that contains all docs, and\n",
    "   it passes (each document, its doc-label) to to our class \"DocIterator\" to \"yield\" a list of those two lists.\n",
    "'''\n",
    "\n",
    "iter_docs = DocIterator(data, docLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' KEY--\n",
    "\n",
    "    size      : is the dimensionality of the feature vectors = 100; 100 weights or features(w0,w1,w2......w99)\n",
    "    window    : is the maximum distance between the current and predicted word within a sentence.\n",
    "    min_count : times the word occurs in all sentences, set to min_count=1 (makes a vocab of all unique words)\n",
    "    workers   :\n",
    "    alpha     : \n",
    "'''\n",
    "\n",
    "## Training our model with our input data\n",
    "model = Doc2Vec(iter_docs, size=500, window=10, min_count=1, workers=11, alpha=0.025, min_alpha=0.025, dbow_words = 1, iter = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('doc2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_loaded = gensim.models.Doc2Vec.load('doc2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Book_2', -0.004399042576551437), ('Book_3', -0.03813797980546951)]\n"
     ]
    }
   ],
   "source": [
    "# Comparing it with other documents\n",
    "print(model.docvecs.most_similar(['Book_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book_2\n"
     ]
    }
   ],
   "source": [
    "# Most similar document\n",
    "print(model.docvecs.most_similar(['Book_1'],topn=1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('after...', 0.18889042735099792),\n",
       " ('Okay,', 0.18032433092594147),\n",
       " ('Amazing!', 0.1711585968732834),\n",
       " ('inch-', 0.16916677355766296),\n",
       " ('\"Scabbers', 0.1685291975736618),\n",
       " ('escorted', 0.16335710883140564),\n",
       " ('FIFTEEN', 0.156924307346344),\n",
       " ('many-armed', 0.15507975220680237),\n",
       " ('memorized', 0.15472283959388733),\n",
       " ('treating', 0.1536206752061844)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing it with other words\n",
    "model.most_similar('Azkaban')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.matutils.cossim(data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finding the similarity between a NEW sentence and docs\n",
    "\n",
    "test = '''At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs.\n",
    "Dursley on the cheek, and tried to kiss Dudley good-bye but missed,\n",
    "because Dudley was now having a tantrum and throwing his cereal at the\n",
    "walls.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = word_tokenize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_doc_vec = model.infer_vector(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Book_2', 0.006374867632985115), ('Book_3', -0.022799234837293625), ('Book_1', -0.03998814895749092)]\n"
     ]
    }
   ],
   "source": [
    "print(model.docvecs.most_similar([new_doc_vec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
